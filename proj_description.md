---
title: "Using OpenAI Codex for Gradual Type Inference"
author: Federico Cassano, Noah Shinn
geometry: "left=3cm,right=3cm,top=3cm,bottom=3cm"
output: pdf_document
---

## Authors and Division of Labor

- Federico Cassano
  - Responsible for designing and implementing the language server protocol and client implementation.
  - Responsible for implementing the TypeScript server.
- Noah Shinn
  - Responsible for designing and implementing an evaluation framework for comparing our system to others.
  - Responsible for implementing the Python server.

## Problem Description and Motivation

Gradually-typed languages are a subset of programming languages that allow optional type annotations. These languages are able to type-check these type annotations. However, these languages are not able to type-check non-annotated sections of code. Some languages such as TypeScript employ a greedy approach to type-inference that only considers operational semantic features. This approach is a viable solution to the problem in smaller sections of code, but the solution may lead to the algorithm falling-back to the `any` or `unknown` types. In the case of `any`, the program will correctly type-check, but the type annotations are undesirable as the type constraints are more permissive. Even worse, in the case of `unknown`, the program will not type-check despite there being a type-checkable solution. Our solution for TypeScript, to target this problem, is to reject the greedy approach in favor of a natural language model technique that uses additional features in the input. These features include, but are not limited to: comments, identifier names, and operational semantics.

## Relevancy to Class Topics

For creating type annotations, we utilize Codex's `davinci-edit` model. `davinci-edit` is a large natural language model that allows users to give a prompt and an instruction as input and produce a modified output (which is the original input with the instruction applied). Natural language processing models are a subset of machine learning, which is a topic covered in this class. We also plan to use search techniques for finding optimal type-checkable solutions for a given program (solutions with the `any` type are considered less optimal).

## Ideal Results and Outcomes

### Minimal Viable Product

Our minimal viable product will be a system that will type-annotate and migrate JavaScript code to TypeScript code as well as simply type-annotate TypeScript code. In the latter case, partially-annotated programs will be turned into strictly-typed programs. We will evaluate the efficacy over a 100-file dataset of Leetcode JavaScript solutions. Our solution will ensure that the output code from Codex will only have type annotations, not other artifacts generated by Codex. Our minimal viable product should be able to correctly type-annotate at least 60% of the given files, where for each file there exists at least one type-checkable solution.

### Stretch-Goal Product

Our stretch goal will be to create a protocol (similar to the Language Server Protocol) that allows type-annotation over an arbitrarily large set of languages. Our solution will utilize different prompt engineering techniques to maximize the quality of the resulting type annotations. Our far-fetched goal is to fine-tune a large language model for our specific task. Finally, we would like to make a VSCode extension that would use our system to type-annotate a portion of user-selected code. We would like our stretch-goal product to beat currently existing probabilistic type-inference systems such as DeepTyper and LambdaNet.

## Milestones + Expected Week-by-Week Schedule

### Milestone 1 - Due 11/4

By now, we will have implemented type-inference for TypeScript using a simple approach that does not involve prompt engineering. This approach will allow us to correctly type-check small files such as Leetcode JavaScript solutions.

### Milestone 2 - Due 11/22

By now, we will have implemented type-inference for Python and a prompt engineering approach that will allow us to type-infer larger files.

### Final Submit - Due 12/13

By the final submission, we will have a strong evaluation framework that allows us to compare our solutions to other type inference systems for the given language. We will also have data created by our framework that shows the efficacy of our solutions. Efficacy will be defined as whether or not the solution type-checks as well as the quality of the type annotations in the solution.
